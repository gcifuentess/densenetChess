{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "densenetChess.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %tensorflow_version 1.x\n",
        "# !pip install h5py==2.10.0 --force-reinstall\n",
        "import os"
      ],
      "metadata": {
        "id": "wx5uligD8e6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "DMpRQGFJ2ULo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = \"/content/drive/My Drive/deepChess/model_densenet.h5\"\n",
        "model_path = \"/content/drive/My Drive/deepChess/model_densenet_tf2.h5\""
      ],
      "metadata": {
        "id": "PzPDHU53-mBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyCtTjfI2aaW"
      },
      "source": [
        "!cp \"/content/drive/My Drive/deepChess/dataset.7z\" /content/dataset.7z\n",
        "!7z e dataset.7z\n",
        "!rm dataset.7z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/My Drive/deepChess/stockfish_14.1_linux_x64.zip\" /content/stockfish_14.1_linux_x64.zip\n",
        "!unzip stockfish_14.1_linux_x64.zip\n",
        "!rm stockfish_14.1_linux_x64.zip\n",
        "!cp /content/stockfish_14.1_linux_x64/stockfish_14.1_linux_x64 /content/stockfish\n",
        "!chmod +x stockfish"
      ],
      "metadata": {
        "id": "H2ZABKQT2eap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn0sCWoHYsbB"
      },
      "source": [
        "!pip install python-chess==0.31.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QauvWk2MkddY"
      },
      "source": [
        "import random\n",
        "import numpy\n",
        "import chess\n",
        "import chess.engine\n",
        "\n",
        "\n",
        "def champion(board, depth):\n",
        "  with chess.engine.SimpleEngine.popen_uci('/content/stockfish') as ch:\n",
        "    analysis = ch.analyse(board, chess.engine.Limit(depth=depth))\n",
        "    score = analysis['score'].white().score()\n",
        "    return score\n",
        "\n",
        "def board_random(depth_max=200):\n",
        "  board = chess.Board()\n",
        "  current_depth = random.randrange(0, depth_max)\n",
        "  # depth = depth_max\n",
        "\n",
        "  for _ in range(current_depth):\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    move = random.choice(legal_moves)\n",
        "    board.push(move)\n",
        "    if board.is_game_over():\n",
        "      break\n",
        "  return board"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0sjAB1A2Y0U"
      },
      "source": [
        "import random\n",
        "random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chess.STARTING_FEN='r7/8/n7/2P4p/Kbkp2NP/8/4n3/8 w - - 0 1'"
      ],
      "metadata": {
        "id": "7s8rqjrsvO5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chess.STARTING_BOARD_FEN= 'r7/8/n7/2P4p/Kbkp2NP/8/4n3/8'"
      ],
      "metadata": {
        "id": "iIP3VEYVv2Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULOEWyyfYqtq"
      },
      "source": [
        "board = board_random()\n",
        "#board = chess.Board('rn6/8/8/2P4p/Kbkp2NP/8/4n3/8 w - - 0 1')\n",
        "board"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtZy4cR8ZMhq"
      },
      "source": [
        "print(champion(board, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMgBRL1Kdc0B"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "We need to represent the board in a way that can be trained so we are going to build a 3D matrix of shape (14, 8, 8). Any chess board has a 8x8 dimension, and to be trainable we are adding a new dimmension of size 14 that will hold 14 boards, 6 for the 6 types of white pieces, 6 for black pieces, and 2 more boards each one of them for the attacked cells for black and white respectebly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdo64dA7dhBE"
      },
      "source": [
        "coordinates = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7}\n",
        "\n",
        "def board_to_index(square):\n",
        "  # for instance: h3 -> 17\n",
        "  letter = chess.square_name(square)\n",
        "  return 8 - int(letter[1]), coordinates[letter[0]]\n",
        "\n",
        "def trainable_board(board):\n",
        "  # the 3d matrix\n",
        "  board_3d = numpy.zeros((14, 8, 8), dtype=numpy.int8)\n",
        "\n",
        "  for piece in chess.PIECE_TYPES:\n",
        "    for square in board.pieces(piece, chess.WHITE):\n",
        "      idx = numpy.unravel_index(square, (8, 8))\n",
        "      board_3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
        "    for square in board.pieces(piece, chess.BLACK):\n",
        "      idx = numpy.unravel_index(square, (8, 8))\n",
        "      board_3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
        "\n",
        "  # add attacked cells and valid moves\n",
        "  temp = board.turn\n",
        "  board.turn = chess.WHITE\n",
        "  for move in board.legal_moves:\n",
        "      i, j = board_to_index(move.to_square)\n",
        "      board_3d[12][i][j] = 1\n",
        "  board.turn = chess.BLACK\n",
        "  for move in board.legal_moves:\n",
        "      i, j = board_to_index(move.to_square)\n",
        "      board_3d[13][i][j] = 1\n",
        "  board.turn = temp\n",
        "\n",
        "  return board_3d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHONl_M1hG9i"
      },
      "source": [
        "trainable_board(board)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukmA7z-dlB6m"
      },
      "source": [
        "# Define the training model\n",
        "We are using the densenet deep learning model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.utils as utils\n",
        "import tensorflow.keras.optimizers as optimizers"
      ],
      "metadata": {
        "id": "vTdQZqOAhnB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as K"
      ],
      "metadata": {
        "id": "Js88eYmQU1-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_block(X, nb_filters, growth_rate, layers):\n",
        "    '''Builds a dense block as described in Densely Connected\n",
        "    Convolutional Networks\n",
        "    Args:\n",
        "        X is the output from the previous layer\n",
        "        nb_filters is an integer representing the number of filters in X\n",
        "        growth_rate is the growth rate for the dense block\n",
        "        layers is the number of layers in the dense block\n",
        "    Important: applied bottleneck layers used for DenseNet-B\n",
        "    Returns: The concatenated output of each layer within the Dense Block\n",
        "             and the number of filters within the concatenated outputs,\n",
        "             respectively\n",
        "    '''\n",
        "    w = K.initializers.he_normal()\n",
        "    concat = X\n",
        "\n",
        "    for i in range(layers):\n",
        "        l1 = K.layers.BatchNormalization()(concat)\n",
        "        l1 = K.layers.Activation(\"relu\")(l1)\n",
        "\n",
        "        l2 = K.layers.Conv2D(filters=(4 * growth_rate),\n",
        "                             kernel_size=(1, 1),\n",
        "                             padding=\"same\",\n",
        "                             data_format=\"channels_first\",\n",
        "                             kernel_initializer=w)(l1)\n",
        "\n",
        "        l3 = K.layers.BatchNormalization()(l2)\n",
        "        l3 = K.layers.Activation(\"relu\")(l3)\n",
        "\n",
        "        l4 = K.layers.Conv2D(filters=growth_rate,\n",
        "                             kernel_size=(3, 3),\n",
        "                             padding=\"same\",\n",
        "                             data_format=\"channels_first\",\n",
        "                             kernel_initializer=w)(l3)\n",
        "\n",
        "        nb_filters += growth_rate\n",
        "        concat = K.layers.Concatenate(axis=1)([concat, l4])\n",
        "\n",
        "    return concat, nb_filters"
      ],
      "metadata": {
        "id": "y0a-seqOU3CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_layer(X, nb_filters, compression):\n",
        "    '''Builds a transition layer as described in Densely Connected\n",
        "    Convolutional Networks\n",
        "    Args:\n",
        "        X is the output from the previous layer\n",
        "        nb_filters is an integer representing the number of filters in X\n",
        "        compression is the compression factor for the transition layer\n",
        "    Returns: The output of the transition layer and the number of filters\n",
        "             within the output, respectively\n",
        "    '''\n",
        "    w = K.initializers.he_normal()\n",
        "\n",
        "    filters = int(compression * nb_filters)\n",
        "\n",
        "    l1 = K.layers.BatchNormalization()(X)\n",
        "    l1 = K.layers.Activation(\"relu\")(l1)\n",
        "\n",
        "    l2 = K.layers.Conv2D(filters=filters,\n",
        "                         kernel_size=(1, 1),\n",
        "                         padding=\"same\",\n",
        "                         data_format=\"channels_first\",\n",
        "                         kernel_initializer=w)(l1)\n",
        "\n",
        "    l3 = K.layers.AveragePooling2D(pool_size=(2, 2),\n",
        "                                   strides=2,\n",
        "                                   data_format=\"channels_first\",\n",
        "                                   padding=\"valid\")(l2)\n",
        "\n",
        "    return l3, filters"
      ],
      "metadata": {
        "id": "3U7WMGVC0A2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_densenet(growth_rate=32, compression=1.0):\n",
        "    '''Builds the DenseNet-121 architecture as described in Densely\n",
        "    Connected Convolutional Networks\n",
        "    Args:\n",
        "        growth_rate is the growth rate\n",
        "        compression is the compression factor\n",
        "    Important: Input data should have shape (224, 224, 3)\n",
        "    Returns: the keras model\n",
        "    '''\n",
        "    w = K.initializers.he_normal()\n",
        "    inputs = K.Input(shape=(14, 8, 8))\n",
        "\n",
        "    sub_layers = [16]\n",
        "\n",
        "    # l1 = K.layers.BatchNormalization()(inputs)\n",
        "    # l1 = K.layers.Activation(\"relu\")(l1)\n",
        "\n",
        "    # l2 = K.layers.Conv2D(filters=64,\n",
        "    #                      kernel_size=(7, 7),\n",
        "    #                      strides=2,\n",
        "    #                      padding=\"same\",\n",
        "    #                      kernel_initializer=w)(l1)\n",
        "\n",
        "    # l3 = K.layers.MaxPool2D(pool_size=(3, 3),\n",
        "    #                         strides=2,\n",
        "    #                         padding=\"same\")(l2)\n",
        "\n",
        "    l4 = inputs\n",
        "    filters = 14\n",
        "    for i in range(1):\n",
        "        l4, filters = dense_block(l4, filters, growth_rate, sub_layers[i])\n",
        "        # if i < 3:\n",
        "        #     l4, filters = transition_layer(l4, filters, compression)\n",
        "\n",
        "    l5 = K.layers.AveragePooling2D(pool_size=(8, 8),\n",
        "                                   strides=1,\n",
        "                                   data_format=\"channels_first\",\n",
        "                                   padding=\"valid\")(l4)\n",
        "\n",
        "    l6 = K.layers.Flatten()(l5)\n",
        "\n",
        "    output = K.layers.Dense(units=1,\n",
        "                            activation=\"sigmoid\",\n",
        "                            kernel_initializer=w)(l6)\n",
        "\n",
        "    return K.Model(inputs=inputs, outputs=output)"
      ],
      "metadata": {
        "id": "-RdozhVGU92o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = custom_densenet(14, 0.5)\n",
        "utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=False)"
      ],
      "metadata": {
        "id": "M_b2Lbq1VOG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck79-w2ZxwVB"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.callbacks as callbacks\n",
        "from sklearn.preprocessing import minmax_scale"
      ],
      "metadata": {
        "id": "qg5YioY7gasW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkOXxmoVyHdc",
        "cellView": "both"
      },
      "source": [
        "def get_dataset():\n",
        "    container = numpy.load('dataset.npz')\n",
        "    bd, v = container['b'], container['v']\n",
        "    arr = numpy.isnan(v)\n",
        "    print(numpy.count_nonzero(arr))\n",
        "    print(v)\n",
        "    print(v.max())\n",
        "    print(v.min())\n",
        "    # v = numpy.asarray((v - v.min()) / (v.max() - v.min() + 1e-4), dtype=numpy.float32) # normalization (0 - 1)\n",
        "    # normalize [a, b]\n",
        "    # a = -1\n",
        "    # b = 1\n",
        "    # v = numpy.asarray(((b - a) * (v - v.min()) / (v.max() - v.min())) + a, dtype=numpy.float32) # normalization (a - b)\n",
        "    v = minmax_scale(v, feature_range=(0, 1))  # 0-1 scaling\n",
        "    print(v)\n",
        "    print(v.max())\n",
        "    print(v.min())\n",
        "    return bd, v\n",
        "\n",
        "x_train, y_train = get_dataset()\n",
        "x_split = int(len(x_train) * 0.8)\n",
        "y_split = int(len(y_train) * 0.8)\n",
        "x_train, x_valid = x_train[:x_split,:,:], x_train[x_split:,:,:]\n",
        "y_train, y_valid = y_train[:y_split], y_train[y_split:]\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model(network, alpha, beta1, beta2):\n",
        "    '''sets up Adam optimization for a keras model with categorical\n",
        "    crossentropy loss and accuracy metrics\n",
        "    Args:\n",
        "        network is the model to optimize\n",
        "        alpha is the learning rate\n",
        "        beta1 is the first Adam optimization parameter\n",
        "        beta2 is the second Adam optimization parameter\n",
        "    Returns: None\n",
        "    '''\n",
        "    optimizer = K.optimizers.Adam(lr=alpha,\n",
        "                                  beta_1=beta1,\n",
        "                                  beta_2=beta2)\n",
        "    network.compile(optimizer=optimizer,\n",
        "                    loss=\"mean_squared_error\",\n",
        "                    metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "3le3p7MJX8DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(network, data, labels, batch_size, epochs,\n",
        "                validation_data=None, early_stopping=False,\n",
        "                patience=0, learning_rate_decay=False, alpha=0.1,\n",
        "                decay_rate=1, save_best=False, filepath=None,\n",
        "                verbose=True, shuffle=False):\n",
        "    '''trains a model using mini-batch gradient descent\n",
        "    Args:\n",
        "        network is the model to train\n",
        "        data is a numpy.ndarray of shape (m, nx) containing the input data\n",
        "        labels is a one-hot numpy.ndarray of shape (m, classes) containing\n",
        "               the labels of data\n",
        "        batch_size is the size of the batch used for mini-batch gradient\n",
        "                   descent\n",
        "        epochs is the number of passes through data for mini-batch gradient\n",
        "               descent\n",
        "        validation_data is the data to validate the model with, if not None\n",
        "        early_stopping is a boolean that indicates whether early stopping\n",
        "                       should be used\n",
        "                       - only performed if validation_data exists\n",
        "                       - based on validation loss\n",
        "        patience is the patience used for early stopping\n",
        "        learning_rate_decay is a boolean that indicates whether learning rate\n",
        "                            decay should be used\n",
        "                            - only performed if validation_data exists\n",
        "                            - performed using inverse time decay\n",
        "                            - decays in a stepwise fashion after each epoch\n",
        "                            - each time the learning rate updates, Keras\n",
        "                              prints a message\n",
        "        alpha is the initial learning rate\n",
        "        decay_rate is the decay rate\n",
        "        save_best is a boolean indicating whether to save the model after each\n",
        "                  epoch if it is the best\n",
        "                  - a model is considered the best if its validation loss is\n",
        "                    the lowest that the model has obtained\n",
        "        filepath is the file path where the model should be saved\n",
        "        verbose is a boolean that determines if output should be printed\n",
        "                during training\n",
        "        shuffle is a boolean that determines whether to shuffle the batches\n",
        "                every epoch. Normally, it is a good idea to shuffle, but for\n",
        "                reproducibility, we have chosen to set the default to False.\n",
        "    Returns: the History object generated after training the model\n",
        "    '''\n",
        "    callbacks = []\n",
        "    if validation_data:\n",
        "        if early_stopping:\n",
        "            early_stop = K.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                   patience=patience)\n",
        "            callbacks.append(early_stop)\n",
        "        if learning_rate_decay:\n",
        "            def schedule(step):\n",
        "                '''stepwise inverse time decay function'''\n",
        "                return alpha * 1 / (1 + decay_rate * step)\n",
        "            lr_decay = K.callbacks.LearningRateScheduler(schedule=schedule,\n",
        "                                                         verbose=1)\n",
        "            callbacks.append(lr_decay)\n",
        "        if save_best:\n",
        "            save_b = K.callbacks.ModelCheckpoint(filepath=filepath,\n",
        "                                                 monitor='val_loss',\n",
        "                                                 save_best_only=True)\n",
        "            callbacks.append(save_b)\n",
        "    return network.fit(x=data,\n",
        "                       y=labels,\n",
        "                       batch_size=batch_size,\n",
        "                       validation_data=validation_data,\n",
        "                       epochs=epochs,\n",
        "                       verbose=verbose,\n",
        "                       callbacks=callbacks,\n",
        "                       shuffle=shuffle)"
      ],
      "metadata": {
        "id": "0BYoqCmPxz6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(model_path):\n",
        "    model = K.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "AyTfzNo39zdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambtha = 0.0001\n",
        "keep_prob = 0.95\n",
        "alpha = 0.001\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "optimize_model(model, alpha, beta1, beta2)\n",
        "batch_size = 64\n",
        "epochs = 1000\n",
        "train_model(model, x_train, y_train, batch_size, epochs,\n",
        "            validation_data=(x_valid, y_valid), early_stopping=True,\n",
        "            patience=3, learning_rate_decay=True, alpha=alpha,\n",
        "            save_best=True, filepath=model_path)"
      ],
      "metadata": {
        "id": "yX4eFq6IYO7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UndQQeUurAKp"
      },
      "source": [
        "# Playing with the AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4CfjcGorHzg"
      },
      "source": [
        "# min_max algorithm\n",
        "def check_min_max(board):\n",
        "  board_3d = trainable_board(board)\n",
        "  board_3d = numpy.expand_dims(board_3d, 0)\n",
        "  return model.predict(board_3d)[0][0]\n",
        "\n",
        "\n",
        "def min_max(board, depth, alpha, beta, maximizing_player):\n",
        "  if depth == 0 or board.is_game_over():\n",
        "    return check_min_max(board)\n",
        "  \n",
        "  if maximizing_player:\n",
        "    max_eval = -numpy.inf\n",
        "    for move in board.legal_moves:\n",
        "      board.push(move)\n",
        "      eval = min_max(board, depth - 1, alpha, beta, False)\n",
        "      board.pop()\n",
        "      max_eval = max(max_eval, eval)\n",
        "      alpha = max(alpha, eval)\n",
        "      if beta <= alpha:\n",
        "        break\n",
        "    return max_eval\n",
        "  else:\n",
        "    min_eval = numpy.inf\n",
        "    for move in board.legal_moves:\n",
        "      board.push(move)\n",
        "      eval = min_max(board, depth - 1, alpha, beta, True)\n",
        "      board.pop()\n",
        "      min_eval = min(min_eval, eval)\n",
        "      beta = min(beta, eval)\n",
        "      if beta <= alpha:\n",
        "        break\n",
        "    return min_eval\n",
        "\n",
        "\n",
        "# function that gets the move from the neural network\n",
        "def get_move(board, depth):\n",
        "  max_move = None\n",
        "  max_eval = -numpy.inf\n",
        "\n",
        "  for move in board.legal_moves:\n",
        "    board.push(move)\n",
        "    eval = min_max(board, depth - 1, -numpy.inf, numpy.inf, False)\n",
        "    #print(move)\n",
        "    #print(\"Eval: \", eval)\n",
        "    #print(\"champion: \", champion(board, 1))\n",
        "    board.pop()\n",
        "    if eval > max_eval:\n",
        "      max_eval = eval\n",
        "      max_move = move\n",
        "  #print(max_eval)\n",
        "  return max_move"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "kmhKe7k8cg8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C63ND0E_uffp"
      },
      "source": [
        "board = chess.Board()\n",
        "\n",
        "with chess.engine.SimpleEngine.popen_uci('/content/stockfish') as engine:\n",
        "  engine.configure({\"Skill Level\": 1})\n",
        "  while True:\n",
        "    move = get_move(board, 1)\n",
        "    board.push(move)\n",
        "    #print(f'\\n{board}')\n",
        "    display(board)\n",
        "    if board.is_game_over():\n",
        "      break\n",
        "\n",
        "    move = engine.analyse(board, chess.engine.Limit(time=1), info=chess.engine.INFO_PV)['pv'][0]\n",
        "    board.push(move)\n",
        "    #print(f'\\n{board}')\n",
        "    display(board)\n",
        "    print(\"\\n\\n\\n\")\n",
        "    if board.is_game_over():\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}